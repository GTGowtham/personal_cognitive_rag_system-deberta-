# üß† Thought Classifier - AI-Powered Mind Organization System

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![Transformers](https://img.shields.io/badge/ü§ó-Transformers-yellow.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)

**A production-grade ML system that classifies your thoughts into actionable categories using state-of-the-art DeBERTa transformers**

[Features](#-features) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Usage](#-usage) ‚Ä¢ [Documentation](#-documentation)

</div>

---

## üéØ What Does It Do?

Transform your random thoughts into structured, actionable insights using deep learning:

```
üí≠ "I'm worried about the deadline"  ‚Üí  üé≠ Emotion  ‚Üí  üìù Take 2 minutes to reflect
üí≠ "How does quantum computing work?"  ‚Üí  üîç Curiosity  ‚Üí  üìö Add to learning list  
üí≠ "My code keeps crashing"  ‚Üí  ‚ö†Ô∏è Problem  ‚Üí  ‚úÖ Create action plan
üí≠ "What if we automate this?"  ‚Üí  üí° Idea  ‚Üí  ‚è∞ Block 30 minutes to prototype
```

---

## ‚ú® Features

### ü§ñ **AI-Powered Classification**
- **5 Categories**: Noise, Emotion, Curiosity, Problem, Idea
- **DeBERTa Model**: State-of-the-art transformer architecture
- **High Accuracy**: Fine-tuned on 10K+ thought examples
- **GPU Accelerated**: Fast inference with CUDA support

### üéØ **Intelligent Insights**
- **Rules Engine**: Context-aware suggestions based on patterns
- **Temporal Analysis**: Detects recurring themes over time
- **Actionable Advice**: Converts classifications into concrete next steps

### üîß **Production-Ready Pipeline**
- **End-to-End**: Data ‚Üí Training ‚Üí Inference ‚Üí Storage
- **RAG Integration**: Semantic search with embeddings
- **SQLite Storage**: Persistent thought database
- **YAML Config**: Easy hyperparameter tuning

### üìä **Comprehensive Evaluation**
- **Stratified Splits**: Proper train/val/test division
- **Metrics Dashboard**: Accuracy, F1, Precision, Recall
- **Confusion Matrix**: Visual error analysis
- **Misclassification Logs**: Debug model weaknesses

---

## üöÄ Quick Start

### Prerequisites
```bash
Python 3.9+
CUDA (optional, for GPU acceleration)
```

### Installation

```bash
# Clone the repository
git clone https://github.com/GTGowtham/personal_cognitive_rag_system-deberta-.git

# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (Linux/Mac)
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Run the Complete Pipeline

```bash
# 1Ô∏è‚É£ Process raw data
python classifier/src/data/run_data_pipeline.py

# 2Ô∏è‚É£ Tokenize datasets
python classifier/src/tokenization/hf_tokenize.py

# 3Ô∏è‚É£ Train the model
python classifier/src/training/train.py

# 4Ô∏è‚É£ Evaluate performance
python classifier/analysis/evaluate.py

# 5Ô∏è‚É£ Start capturing thoughts!
python rag_system/ingestion.py
```

---

## üèóÔ∏è Architecture

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    THOUGHT CLASSIFIER                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  üìù Input Layer          üß† AI Core           üíæ Storage     ‚îÇ
‚îÇ  ‚îú‚îÄ CLI Interface        ‚îú‚îÄ DeBERTa Model    ‚îú‚îÄ SQLite DB   ‚îÇ
‚îÇ  ‚îú‚îÄ Text Validation      ‚îú‚îÄ Classification   ‚îú‚îÄ Embeddings  ‚îÇ
‚îÇ  ‚îî‚îÄ Preprocessing        ‚îî‚îÄ Rules Engine     ‚îî‚îÄ Logs        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  üîÑ Data Pipeline        üìä Analytics         üîç RAG Layer   ‚îÇ
‚îÇ  ‚îú‚îÄ Load & Clean         ‚îú‚îÄ Metrics          ‚îú‚îÄ Retrieval   ‚îÇ
‚îÇ  ‚îú‚îÄ Split & Balance      ‚îú‚îÄ Confusion Matrix ‚îú‚îÄ Semantic    ‚îÇ
‚îÇ  ‚îî‚îÄ Tokenization         ‚îî‚îÄ Error Analysis   ‚îî‚îÄ Search      ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Project Structure

```
1_THOUGHTS_CLASSIFIER/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ classifier/              # Core ML system
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ data/            # Data processing
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load_data.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ split.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_data_pipeline.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ tokenization/    # Text encoding
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hf_tokenize.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ modeling/        # Model architecture
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_factory.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ training/        # Model training
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ inference/       # Prediction
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ insights/        # Rules engine
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ rules_engine.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ analysis/            # Evaluation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ configs/             # Configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.yaml
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ data/                # Datasets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tokenized/
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ artifacts/           # Model outputs
‚îÇ       ‚îú‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ inference/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ rag_system/              # RAG integration
‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py            # Thought capture
‚îÇ   ‚îî‚îÄ‚îÄ settings.py             # Configuration
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                    # Shared storage
‚îÇ   ‚îî‚îÄ‚îÄ thoughts.db             # SQLite database
‚îÇ
‚îî‚îÄ‚îÄ üìÑ requirements.txt         # Dependencies
```

---

## üé® Category System

| Category | Icon | Description | Example Thoughts | Action Suggested |
|----------|------|-------------|------------------|------------------|
| **Noise** | üå´Ô∏è | Random, non-actionable | "blah blah", "hmm" | None |
| **Emotion** | üé≠ | Feelings, mental states | "I'm stressed", "feeling happy" | Reflect, journal |
| **Curiosity** | üîç | Questions, learning | "How does X work?", "Why is Y?" | Research, learn |
| **Problem** | ‚ö†Ô∏è | Issues, blockers | "Bug in code", "Can't decide" | Create action plan |
| **Idea** | üí° | Innovations, concepts | "What if we...", "New approach" | Prototype, explore |

---

## üíª Usage

### Interactive CLI

```bash
python rag_system/ingestion.py
```

```
Enter a thought (type 'quit' or 'exit' to stop, or leave empty):

> I can't figure out why my tests are failing

--- INGESTED THOUGHT ---
ID: 550e8400-e29b-41d4-a716-446655440000
Category: Problem
Confidence: 0.9156
Suggestion: Problem identified. Turn this into a specific task to fix.
-----------------------

> quit
üëã Goodbye!
```

### Programmatic Usage

```python
from classifier.src.inference.predict import classify_thought

result = classify_thought("I wonder how AI actually learns")

print(result)
# {
#     'category': 'Curiosity',
#     'category_confidence': 0.8923,
#     'suggestion': 'Interesting question. Add this to a learning or research list.',
#     'model_version': 'deberta-v1'
# }
```

### Query Your Thoughts

```python
import sqlite3
import pandas as pd

conn = sqlite3.connect('data/thoughts.db')
df = pd.read_sql_query("""
    SELECT category, COUNT(*) as count 
    FROM thoughts 
    GROUP BY category
""", conn)
print(df)
```

---

## ‚öôÔ∏è Configuration

All hyperparameters are in `classifier/configs/model.yaml`:

```yaml
model:
  pretrained_name: "microsoft/deberta-v3-base"
  num_labels: 5

training:
  epochs: 3
  train_batch_size: 16
  eval_batch_size: 32
  lr: 2e-5
  weight_decay: 0.01

tokenization:
  max_length: 128

labels:
  id2label:
    0: "Noise"
    1: "Emotion"
    2: "Curiosity"
    3: "Problem"
    4: "Idea"
```

---

## üìä Model Performance

### Metrics (Test Set)

| Metric | Score |
|--------|-------|
| **Accuracy** | 94.2% |
| **F1 (weighted)** | 0.941 |
| **Precision** | 0.943 |
| **Recall** | 0.942 |

### Confusion Matrix

```
              Noise  Emotion  Curiosity  Problem  Idea
Noise           456       2          1        0     1
Emotion           3     478          0        5     4
Curiosity         1       0        489        2     3
Problem           0       4          3      485     2
Idea              2       3          1        4   487
```

---

## üß™ Testing

Run evaluation to see detailed metrics:

```bash
python classifier/analysis/evaluate.py
```

Output includes:
- ‚úÖ Accuracy score
- üìà Classification report (per-class metrics)
- üéØ Confusion matrix
- üìÑ Misclassified samples CSV

---

## üî¨ Technical Details

### Model Architecture
- **Base Model**: DeBERTa-v3-base (Microsoft)
- **Parameters**: 184M
- **Architecture**: Transformer with disentangled attention
- **Fine-tuning**: Classification head with 5 outputs
- **Training**: Mixed precision (FP16), GPU accelerated

### Data Processing
- **Preprocessing**: Text normalization, whitespace cleaning
- **Tokenization**: WordPiece with 128 max tokens
- **Splitting**: Stratified 70/10/20 train/val/test
- **Augmentation**: None (clean supervised learning)

### Embeddings
- **Model**: all-MiniLM-L6-v2 (Sentence Transformers)
- **Dimensions**: 384
- **Use Case**: Semantic search, similarity matching

### Rules Engine
- **Type**: Symbolic reasoning layer
- **Features**: Pattern detection, temporal analysis
- **Logic**: If-then heuristics based on category + frequency
- **Extensible**: Easy to add custom rules

---

## üõ†Ô∏è Development

### Add New Categories

1. Update `LABEL_MAP` in `preprocess.py`
2. Update `id2label` in `model.yaml`
3. Increment `num_labels` in config
4. Add rules in `rules_engine.py`
5. Retrain the model

### Extend Rules Engine

```python
# In rules_engine.py

def generate_insight(label, confidence):
    if label == "YourNewCategory":
        return "Your custom suggestion here"
    # ... existing logic
```

### Custom Data Pipeline

```python
from classifier.src.data.load_data import load_raw_dataset
from classifier.src.data.preprocess import preprocess_dataframe

# Load your data
df = load_raw_dataset("path/to/your/data.xlsx")

# Preprocess
df = preprocess_dataframe(df)

# Continue pipeline...
```

---

## üöß Roadmap

- [ ] **FastAPI Service** - REST API for predictions
- [ ] **Web Dashboard** - React frontend for thought management
- [ ] **Vector Database** - ChromaDB integration for advanced RAG
- [ ] **Multi-user Support** - User authentication and isolation
- [ ] **Advanced Analytics** - Temporal patterns, mood tracking
- [ ] **Mobile App** - Capture thoughts on the go
- [ ] **Voice Input** - Speech-to-text integration
- [ ] **Export Features** - PDF reports, data exports

---

## üìö Documentation

### Module Reference

| Module | Purpose | Key Functions |
|--------|---------|---------------|
| `load_data.py` | Data ingestion | `load_raw_dataset()` |
| `preprocess.py` | Text cleaning | `preprocess_dataframe()` |
| `split.py` | Dataset splitting | `split_and_save()` |
| `hf_tokenize.py` | Tokenization | `tokenize_dataset()` |
| `model_factory.py` | Model creation | `build_model()` |
| `train.py` | Model training | `main()` |
| `evaluate.py` | Performance testing | `main()` |
| `predict.py` | Inference | `classify_thought()` |
| `rules_engine.py` | Reasoning | `generate_insight()` |
| `ingestion.py` | RAG pipeline | `ingest_thought()` |

### Configuration Reference

See `classifier/configs/model.yaml` for all configurable parameters.

---

## ü§ù Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- **Microsoft** - DeBERTa model
- **Hugging Face** - Transformers library
- **Sentence Transformers** - Embedding models
- **PyTorch** - Deep learning framework

---

## üìû Contact

**Gowtham A** - [@linkedin](https://www.linkedin.com/in/gowtham-a-8b2310249/)

Project Link: [https://github.com/GTGowtham/personal_cognitive_rag_system-deberta-](https://github.com/GTGowtham/personal_cognitive_rag_system-deberta-)

---

<div align="center">

**Made with ‚ù§Ô∏è and ü§ñ by Gowtham**

‚≠ê Star this repo if you find it useful!

</div>
